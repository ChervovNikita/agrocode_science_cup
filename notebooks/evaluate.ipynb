{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d7889b7-9cf0-469d-83a8-37a598096632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chervovn04/Programming/hackathons/2022\n"
     ]
    }
   ],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ab040da9-2e50-4257-bb40-dad33368f347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from PIL import Image\n",
    "from collections import Counter, OrderedDict\n",
    "%matplotlib inline\n",
    "%matplotlib widget\n",
    "\n",
    "from glob import glob\n",
    "from sklearn.metrics import *\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0, EfficientNetB1, preprocess_input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from model_structure import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58b7eeca-6398-4e45-93ef-ccdde2e4de09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu for inference\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f'Using {device} for inference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21a9c2fb-6109-4c46-8379-ec38bee3ba1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AP(relevance):\n",
    "    Ps = []\n",
    "    count = 0\n",
    "    for i, val in enumerate(relevance):\n",
    "        i += 1\n",
    "        if val:\n",
    "            count += 1\n",
    "            Ps.append(count / i)\n",
    "    if not Ps:\n",
    "        Ps = [0]\n",
    "    return sum(Ps) / len(Ps)\n",
    "\n",
    "def mAP(relevances):\n",
    "    return sum([AP(relevance) for relevance in relevances]) / len(relevances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74259df9-f00c-4d52-87a2-f4f30d4ad488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(path, models_data):    \n",
    "    with torch.no_grad():\n",
    "        features = []\n",
    "        for model, tfm in models_data:\n",
    "            image = Image.open(path).convert('RGB')\n",
    "            image = tfm(image)\n",
    "\n",
    "            image = image[None, :, :, :]\n",
    "                        \n",
    "            pred = np.array(model(image).detach()).squeeze()\n",
    "\n",
    "            features.append(pred)\n",
    "        features = np.concatenate(features, axis=0)\n",
    "        features /= np.linalg.norm(features)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6375f6e-510a-4352-a329-949e862d5fab",
   "metadata": {},
   "outputs": [],
   "source": [
    " def get_emb(data, models_data, base_dir='data/train/'):\n",
    "    emb = []\n",
    "    for idx in tqdm(data.idx):\n",
    "        emb.append(extract_features(f'{base_dir}{idx}.png', models_data))\n",
    "    emb = np.array(emb)\n",
    "    return emb\n",
    "        \n",
    "def evaluate(db, que, db_emb, que_emb, need_processing=0):\n",
    "    if need_processing:\n",
    "        db = process(db)\n",
    "        que = process(que)\n",
    "    \n",
    "    neigh = NearestNeighbors(n_neighbors=10, metric='cosine')\n",
    "    neigh.fit(db_emb)\n",
    "    \n",
    "    distances, idxs = neigh.kneighbors(que_emb, 10, return_distance=True)\n",
    "    relevances = []\n",
    "    for i in range(idxs.shape[0]):\n",
    "        name = que.item_nm.iloc[i]\n",
    "        que_rec = idxs[i]\n",
    "        \n",
    "        relevance = []\n",
    "        for idx in que_rec:\n",
    "            relevance.append(name == db.item_nm.iloc[idx])\n",
    "        relevances.append(relevance)\n",
    "    return mAP(relevances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "faf51f74-7c8e-4d3c-98f2-1f966ccef042",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/train.csv')\n",
    "db, que = train_test_split(data, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3999871a-ed57-4b80-9eb1-6c5191bf4dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViT_H_Wrapper(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x.pooler_output\n",
    "    \n",
    "class SiameseModel(nn.Module):\n",
    "    def __init__(self, extractor):\n",
    "        super().__init__()\n",
    "        self.extractor = extractor\n",
    "    def forward(self, image_0, image_1):\n",
    "        return self.extractor(image_0), self.extractor(image_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "beeb64ae-a9ea-4f41-bf44-7b8c4e141663",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vit_model(path):\n",
    "    model = torch.load(path, map_location=torch.device('cpu'))\n",
    "    model.eval()\n",
    "    model.fc = Identical()\n",
    "    return model\n",
    "\n",
    "def get_HF_vit_model(path):\n",
    "    vit = torch.load(path, map_location=torch.device('cpu'))\n",
    "    vit.eval()\n",
    "    model = ViT_H_Wrapper(vit)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def common_load(path):\n",
    "    model = torch.load(path, map_location=torch.device('cpu'))\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d4cec8ac-8bd4-48c4-8c89-4c1edd89e899",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    (get_vit_model('weights/resnext101_32x48.pt'), transforms.Compose([\n",
    "        # transforms.Resize(224), \n",
    "        # transforms.CenterCrop(224), \n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "    ])),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f61aa289-2f5d-4a22-b8a2-4a5adcf50ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 3900/3900 [3:37:46<00:00,  3.35s/it]\n",
      "100%|█████████████████████████████████████████| 976/976 [53:41<00:00,  3.30s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.08245255849379832"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_emb = get_emb(db, models)\n",
    "que_emb = get_emb(que, models)\n",
    "evaluate(db, que, db_emb, que_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acc2836-f9ea-457e-bdab-78b731510fab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbe189b-cc73-4e76-b744-e2792bcf9ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b610db9-bc5d-4b73-908a-8b3c0d0a40cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34a32f3-3b12-4997-bb61-b0a02ffac9c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1573e63-66f6-4daf-85d8-d05e21084629",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b719f78-4cce-4255-9f08-7cc8c874b47e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f709cf-75af-49e2-aa06-28bbce23aad3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c274f26-99b3-434c-9eb2-c31802080184",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c90a2a-1e44-4af6-9c1c-ceed1310d7bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7aa06d-1b55-4f17-ae39-7864726ced9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # shapes = (224, 240, 260, 300, 380, 456, 528)\n",
    "\n",
    "# model = load_model('weights/efficientnetb0.h5')\n",
    "\n",
    "# emb_finders = [\n",
    "#     ('efficientnetb0', ('avg_pool', 'block7a_se_reshape'), 3, 224),\n",
    "#     ('efficientnetb1', ('avg_pool', 'block7a_se_reshape', 'block7b_se_reshape'), 2, 240),\n",
    "#     ('efficientnetb2', ('avg_pool', 'block7a_se_reshape', 'block7b_se_reshape'), 2, 260),\n",
    "#     ('efficientnetb3', ('avg_pool', 'block7a_se_reshape', 'block7b_se_reshape'), 2, 300)\n",
    "# ]\n",
    "\n",
    "# models_data = []\n",
    "# for model_type, layers, coef, shape in emb_finders:\n",
    "#     model = load_model(f'weights/{model_type}.h5')\n",
    "#     for layer in layers:\n",
    "#         models_data.append((\n",
    "#             Model(inputs=model.input, outputs=model.get_layer(layer).output),\n",
    "#             (shape, shape),\n",
    "#             coef\n",
    "#         ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582ba9ca-ad62-457b-874a-f6ddf849dab8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97689b34-cc2c-45c0-98df-5f04fa2cf673",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
