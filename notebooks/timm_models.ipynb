{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03d5c319-ed2b-44ba-93c4-b5551f90a320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chervovn04/Programming/hackathons/2022/agrocode\n"
     ]
    }
   ],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cde7057-629d-4f97-9b39-62af4f395d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from PIL import Image\n",
    "from collections import Counter, OrderedDict\n",
    "%matplotlib inline\n",
    "%matplotlib widget\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from model_structure import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "919f8b5f-26a5-4624-8254-fc499f8eba8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce5a3da0-da8b-4c4b-8e44-0d3080cbc491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu for inference\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f'Using {device} for inference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa519b27-e02c-4879-bc8b-ff971f0e33c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AP(relevance):\n",
    "    Ps = []\n",
    "    count = 0\n",
    "    for i, val in enumerate(relevance):\n",
    "        i += 1\n",
    "        if val:\n",
    "            count += 1\n",
    "            Ps.append(count / i)\n",
    "    if not Ps:\n",
    "        Ps = [0]\n",
    "    return sum(Ps) / len(Ps)\n",
    "\n",
    "def mAP(relevances):\n",
    "    return sum([AP(relevance) for relevance in relevances]) / len(relevances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be5b2ea6-f7e0-47ca-ae81-a880fbd7a61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(path, models_data):    \n",
    "    with torch.no_grad():\n",
    "        features = []\n",
    "        for model, tfm, coef in models_data:\n",
    "            image = Image.open(path).convert('RGB')\n",
    "            image = tfm(image)\n",
    "\n",
    "            image = image[None, :, :, :].to(device)\n",
    "                        \n",
    "            pred = np.array(model(image).detach().cpu()).squeeze() * coef\n",
    "            # pred = np.random.rand(100) * coef\n",
    "            features.append(pred)\n",
    "            \n",
    "        features = np.concatenate(features, axis=0)\n",
    "        features /= np.linalg.norm(features)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cf47177-c2a9-4fe0-881c-7fc6f26b3a04",
   "metadata": {},
   "outputs": [],
   "source": [
    " def get_emb(data, models_data, base_dir):\n",
    "    emb = []\n",
    "    for idx in tqdm(data.idx):\n",
    "        emb.append(extract_features(f'{base_dir}{idx}.png', models_data))\n",
    "    emb = np.array(emb)\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2eef7087-3e92-4d09-80c9-fd7300fc0646",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/train.csv')\n",
    "db, que = train_test_split(data, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f40f5ba6-3e85-460b-9e8d-9765a7a22ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_head_fc(path):\n",
    "    model = torch.load(path, map_location=torch.device(device))\n",
    "    model.head.fc = Identical()\n",
    "    return model\n",
    "\n",
    "def model_head(path):\n",
    "    model = torch.load(path, map_location=torch.device(device))\n",
    "    model.head = Identical()\n",
    "    return model\n",
    "\n",
    "def model_fc(path):\n",
    "    model = torch.load(path, map_location=torch.device(device))\n",
    "    model.fc = Identical()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f1a95e0-4629-4f41-b1b7-f8f928d1ee79",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_data = []\n",
    "\n",
    "model = model_head('weights/beit_finetuned_9.pth')\n",
    "transform = transforms.Compose([ transforms.Resize(224), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]) ])\n",
    "models_data.append((model, transform, 1))\n",
    "\n",
    "for model, transform, coef in models_data:\n",
    "    model.eval()\n",
    "    model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0052510a-678c-42c7-98e4-35bf406f83d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_double_spaces(nm):\n",
    "    new_nm = ''\n",
    "    for char in nm:\n",
    "        if char != ' ' or (len(new_nm) and new_nm[-1] != ' '):\n",
    "            new_nm += char\n",
    "    return new_nm.strip()\n",
    "\n",
    "def label_process(nm):\n",
    "    # 1. to lower\n",
    "    nm = nm.lower()\n",
    "    \n",
    "    # 2. delete useless sequences\n",
    "    for todel in [';', '&quot']:\n",
    "        nm = nm.replace(todel, '')\n",
    "        \n",
    "    # 3. delete text in parenthesis\n",
    "    new_nm = ''\n",
    "    balance = 0\n",
    "    for char in nm:\n",
    "        if char == '(':\n",
    "            balance += 1\n",
    "        elif char == ')':\n",
    "            balance = max(0, balance - 1)\n",
    "        elif balance == 0:\n",
    "            new_nm += char\n",
    "    nm = new_nm\n",
    "    \n",
    "    # 4. only russian symbols\n",
    "    new_nm = ''\n",
    "    for char in nm:\n",
    "        if char in 'йцукенгшщзхъфывапролджэячсмитьбю ':\n",
    "            new_nm += char\n",
    "    nm = delete_double_spaces(new_nm)\n",
    "    \n",
    "    # 6. delete useless \"words\"\n",
    "    # 7. convert every word to the origin form \n",
    "    \n",
    "    new_nm = ''\n",
    "    black_list = ['х', 'хх', 'ххх', 'мм', 'с', 'км', 'от', 'в', 'т']\n",
    "    for word in nm.split(' '):\n",
    "        if word not in black_list and len(word) > 2:\n",
    "            word = morph.parse(word)[0].normal_form \n",
    "            new_nm += word + ' '\n",
    "    nm = delete_double_spaces(new_nm)\n",
    "    \n",
    "    return nm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9bfb6b83-b3a1-4db6-9f7c-83b925375931",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelInfo:\n",
    "    def __init__(self, label):\n",
    "        self.label = label\n",
    "        self.ids = []\n",
    "        self.extra_embs = []\n",
    "        self.embs = []\n",
    "        self.mean_emb = None\n",
    "        self.neigh = None\n",
    "    \n",
    "    def add(self, idx, emb):\n",
    "        self.ids.append(idx)\n",
    "        self.embs.append(emb)\n",
    "    \n",
    "    def process(self):\n",
    "        for i in range(len(self.embs)):\n",
    "            self.embs[i] = self.embs[i][None, :]\n",
    "        self.embs = np.concatenate(self.embs, axis=0)       \n",
    "        \n",
    "        self.mean_emb = np.median(self.embs, axis=0)\n",
    "        \n",
    "        self.neigh = NearestNeighbors(n_neighbors=min(10, self.embs.shape[0]), metric='cosine')        \n",
    "        self.neigh.fit(self.embs)\n",
    "        \n",
    "        return self.mean_emb\n",
    "        \n",
    "    def get_best_ids(self, emb, k):\n",
    "        if not k:\n",
    "            return np.array([]), np.array([], dtype=int)\n",
    "        k = min(k, self.embs.shape[0])\n",
    "        distances, idxs = self.neigh.kneighbors(emb[None, :], k, return_distance=True)\n",
    "        distances = distances[0]\n",
    "        idxs = idxs[0]\n",
    "        for i in range(k):\n",
    "            idxs[i] = self.ids[idxs[i]]\n",
    "            distances[i] += k\n",
    "        return distances, idxs\n",
    "\n",
    "        \n",
    "def get_result(db, que, models_data, db_dir='data/test/', que_dir='data/queries'):\n",
    "    label2id = {}\n",
    "    id2label = []\n",
    "    \n",
    "    label_info = []\n",
    "    \n",
    "    db_emb = get_emb(db, models_data, db_dir)\n",
    "    que_emb = get_emb(que, models_data, que_dir)\n",
    "    \n",
    "    for (_, row), emb in zip(db.iterrows(), db_emb):\n",
    "        idx = row.idx\n",
    "        label = row.item_nm\n",
    "        \n",
    "        label = label_process(label)\n",
    "        \n",
    "        if label not in label2id:\n",
    "            label2id[label] = len(id2label)\n",
    "            id2label.append(label)\n",
    "            label_info.append(LabelInfo(label))\n",
    "        label_info[label2id[label]].add(idx, emb)\n",
    "    \n",
    "    new_label2id = {}\n",
    "    new_id2label = []\n",
    "    new_label_info = []\n",
    "    \n",
    "    for i in range(len(label_info)):\n",
    "        if len(label_info[i].embs) > 3:\n",
    "            new_id2label.append(label_info[i].label)\n",
    "            new_label2id[label_info[i].label] = len(new_label2id)\n",
    "            new_label_info.append(label_info[i])\n",
    "    \n",
    "    label2id = new_label2id\n",
    "    id2label = new_id2label\n",
    "    label_info = new_label_info\n",
    "    \n",
    "    general_emb = []\n",
    "    for i in range(len(label_info)):\n",
    "        general_emb.append(label_info[i].process())\n",
    "    general_emb = np.array(general_emb)\n",
    "        \n",
    "    general_neigh = NearestNeighbors(n_neighbors=10, metric='cosine')\n",
    "    general_neigh.fit(general_emb)\n",
    "    \n",
    "    folder_ids = general_neigh.kneighbors(que_emb, 10, return_distance=False)\n",
    "    \n",
    "    result = []\n",
    "    for i, que_idx in enumerate(que.idx):\n",
    "        ids = folder_ids[i]\n",
    "        distances = np.array([])\n",
    "        db_ids = np.array([], dtype=int)\n",
    "        for label_id in ids:\n",
    "            res = label_info[label_id].get_best_ids(que_emb[i], 10 - distances.shape[0])\n",
    "            distances = np.concatenate([distances, res[0]])\n",
    "            db_ids = np.concatenate([db_ids, res[1]])\n",
    "        for j in range(10):\n",
    "            result.append((que_idx, db_ids[j], distances[j]))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21d54938-39fa-490f-acf5-3757ecf4e41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(result, db, que):\n",
    "    get_label_db = {}\n",
    "    get_label_que = {}\n",
    "    for _, row in db.iterrows():\n",
    "        idx = row.idx\n",
    "        label = row.item_nm\n",
    "        get_label_db[idx] = label\n",
    "    for _, row in que.iterrows():\n",
    "        idx = row.idx\n",
    "        label = row.item_nm\n",
    "        get_label_que[idx] = label\n",
    "    \n",
    "    relevant_db = {}\n",
    "    for que_idx, db_idx, distance in result:\n",
    "        if que_idx not in relevant_db:\n",
    "            relevant_db[que_idx] = []\n",
    "        relevant_db[que_idx].append((db_idx, distance))\n",
    "    relevances = []\n",
    "        \n",
    "    for key, value in relevant_db.items():\n",
    "        value = sorted(value, key=lambda x : x[1], reverse=True)\n",
    "        value = [item[0] for item in value]\n",
    "        que_label = get_label_que[key]\n",
    "        relevance = [que_label == get_label_db[db_idx] for db_idx in value]\n",
    "        relevances.append(relevance)\n",
    "    \n",
    "    return mAP(relevances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb81a318-3e3e-434c-9034-1b7f577da68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                        | 12/3900 [00:07<41:05,  1.58it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mque\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/train/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/train/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36mget_result\u001b[0;34m(db, que, models_data, db_dir, que_dir)\u001b[0m\n\u001b[1;32m     41\u001b[0m id2label \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     43\u001b[0m label_info \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 45\u001b[0m db_emb \u001b[38;5;241m=\u001b[39m \u001b[43mget_emb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m que_emb \u001b[38;5;241m=\u001b[39m get_emb(que, models_data, que_dir)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (_, row), emb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(db\u001b[38;5;241m.\u001b[39miterrows(), db_emb):\n",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36mget_emb\u001b[0;34m(data, models_data, base_dir)\u001b[0m\n\u001b[1;32m      2\u001b[0m emb \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m tqdm(data\u001b[38;5;241m.\u001b[39midx):\n\u001b[0;32m----> 4\u001b[0m     emb\u001b[38;5;241m.\u001b[39mappend(\u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mbase_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43midx\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels_data\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      5\u001b[0m emb \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(emb)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m emb\n",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36mextract_features\u001b[0;34m(path, models_data)\u001b[0m\n\u001b[1;32m      6\u001b[0m image \u001b[38;5;241m=\u001b[39m tfm(image)\n\u001b[1;32m      8\u001b[0m image \u001b[38;5;241m=\u001b[39m image[\u001b[38;5;28;01mNone\u001b[39;00m, :, :, :]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 10\u001b[0m pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu())\u001b[38;5;241m.\u001b[39msqueeze() \u001b[38;5;241m*\u001b[39m coef\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# pred = np.random.rand(100) * coef\u001b[39;00m\n\u001b[1;32m     12\u001b[0m features\u001b[38;5;241m.\u001b[39mappend(pred)\n",
      "File \u001b[0;32m~/Programming/hackathons/2022/agrocode/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Programming/hackathons/2022/agrocode/venv/lib/python3.10/site-packages/timm/models/beit.py:342\u001b[0m, in \u001b[0;36mBeit.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 342\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_head(x)\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/Programming/hackathons/2022/agrocode/venv/lib/python3.10/site-packages/timm/models/beit.py:329\u001b[0m, in \u001b[0;36mBeit.forward_features\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    327\u001b[0m         x \u001b[38;5;241m=\u001b[39m checkpoint(blk, x, shared_rel_pos_bias\u001b[38;5;241m=\u001b[39mrel_pos_bias)\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 329\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshared_rel_pos_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrel_pos_bias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    330\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(x)\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/Programming/hackathons/2022/agrocode/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Programming/hackathons/2022/agrocode/venv/lib/python3.10/site-packages/timm/models/beit.py:196\u001b[0m, in \u001b[0;36mBlock.forward\u001b[0;34m(self, x, shared_rel_pos_bias)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma_1 \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x), shared_rel_pos_bias\u001b[38;5;241m=\u001b[39mshared_rel_pos_bias))\n\u001b[0;32m--> 196\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma_2 \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/Programming/hackathons/2022/agrocode/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Programming/hackathons/2022/agrocode/venv/lib/python3.10/site-packages/timm/models/layers/mlp.py:30\u001b[0m, in \u001b[0;36mMlp.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(x)\n\u001b[1;32m     29\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop1(x)\n\u001b[0;32m---> 30\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop2(x)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/Programming/hackathons/2022/agrocode/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Programming/hackathons/2022/agrocode/venv/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "result = get_result(db, que, models_data, 'data/train/', 'data/train/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "be7fb1a7-0d58-46bb-aee8-b4b07a37525d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005441294326625612"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(result, db, que)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee9aea8-d17c-4f2a-969f-59dabbdcff84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c17be2e-8c94-4010-bab0-1e62069e6585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f980d7a-cffa-411b-a2ad-9e149d3f728c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7feb071e-fd37-4803-be0c-6c53238ccd20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c4d659-ae6e-4a3d-91b8-af37a2b6afc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca0eb05-eebd-4f6f-b673-c53c26c31c06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
